{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qqW-aZShkwST",
        "outputId": "25b14a56-d633-4fde-946a-9d920f8fa25a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:55<00:00, 3.09MB/s]\n",
            "Epoch 1/100 [Train]: 100%|██████████| 196/196 [02:06<00:00,  1.55it/s, acc=9.55%, loss=2.43]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎉 New best accuracy at epoch 1: 9.94%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/100 [Train]: 100%|██████████| 196/196 [02:11<00:00,  1.49it/s, acc=24.93%, loss=2.03]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎉 New best accuracy at epoch 2: 37.78%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=32.84%, loss=1.83]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎉 New best accuracy at epoch 3: 40.42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=36.24%, loss=1.75]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎉 New best accuracy at epoch 4: 44.00%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=37.31%, loss=1.73]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎉 New best accuracy at epoch 5: 45.21%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/100 [Train]: 100%|██████████| 196/196 [02:11<00:00,  1.49it/s, acc=35.81%, loss=1.76]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Test Accuracy: 43.38% (Best: 45.21%)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=36.11%, loss=1.76]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Test Accuracy: 42.61% (Best: 45.21%)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=34.39%, loss=1.79]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Test Accuracy: 42.59% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100 [Train]: 100%|██████████| 196/196 [02:11<00:00,  1.49it/s, acc=34.73%, loss=1.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Test Accuracy: 42.41% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=34.19%, loss=1.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Test Accuracy: 43.82% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100 [Train]: 100%|██████████| 196/196 [02:11<00:00,  1.49it/s, acc=35.44%, loss=1.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Test Accuracy: 42.62% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100 [Train]: 100%|██████████| 196/196 [02:11<00:00,  1.49it/s, acc=35.00%, loss=1.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Test Accuracy: 45.07% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=35.07%, loss=1.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Test Accuracy: 42.95% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100 [Train]: 100%|██████████| 196/196 [02:11<00:00,  1.49it/s, acc=34.93%, loss=1.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Test Accuracy: 45.08% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=35.96%, loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Test Accuracy: 44.88% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=37.02%, loss=1.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Test Accuracy: 44.86% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=36.50%, loss=1.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Test Accuracy: 43.85% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100 [Train]: 100%|██████████| 196/196 [02:11<00:00,  1.49it/s, acc=36.15%, loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Test Accuracy: 43.39% (Best: 45.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=36.74%, loss=1.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 New best accuracy at epoch 19: 46.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100 [Train]: 100%|██████████| 196/196 [02:11<00:00,  1.49it/s, acc=36.97%, loss=1.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Test Accuracy: 45.07% (Best: 46.61%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=37.64%, loss=1.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 New best accuracy at epoch 21: 46.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100 [Train]: 100%|██████████| 196/196 [02:12<00:00,  1.48it/s, acc=37.49%, loss=1.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Test Accuracy: 45.61% (Best: 46.93%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100 [Train]:  36%|███▌      | 70/196 [00:48<01:27,  1.44it/s, acc=37.89%, loss=1.71]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-929337858.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0mcurrent_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-929337858.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Cell 1: Imports and Setup\n",
        "# ==============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Cell 2: Configuration\n",
        "# ==============================================================================\n",
        "config = {\n",
        "    \"patch_size\": 4,\n",
        "    \"image_size\": 32,\n",
        "    \"in_channels\": 3,\n",
        "    \"embed_dim\": 512,\n",
        "    \"num_heads\": 8,\n",
        "    \"mlp_ratio\": 4.0,\n",
        "    \"depth\": 6,\n",
        "    \"num_classes\": 10,\n",
        "    \"dropout_rate\": 0.1,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"weight_decay\": 0.05,\n",
        "    \"batch_size\": 256,\n",
        "    \"num_epochs\": 100,\n",
        "    \"warmup_epochs\": 5,\n",
        "}\n",
        "\n",
        "# ==============================================================================\n",
        "# Cell 3: Building Blocks for the Vision Transformer (ViT)\n",
        "# ==============================================================================\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, image_size, patch_size, in_channels, embed_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = (image_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n",
        "        self.attn_drop = nn.Dropout(dropout_rate)\n",
        "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.proj_drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = (q @ k.transpose(-2, -1)) * (self.head_dim ** -0.5)\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, D)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, mlp_ratio, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = MultiHeadAttention(embed_dim, num_heads, dropout_rate)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        mlp_hidden_dim = int(embed_dim * mlp_ratio)\n",
        "        self.mlp = MLP(embed_dim, mlp_hidden_dim, embed_dim, dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "# ==============================================================================\n",
        "# Cell 4: The Full Vision Transformer (ViT) Model\n",
        "# ==============================================================================\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbedding(config[\"image_size\"], config[\"patch_size\"], config[\"in_channels\"], config[\"embed_dim\"])\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, config[\"embed_dim\"]))\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, config[\"embed_dim\"]))\n",
        "        self.pos_drop = nn.Dropout(config[\"dropout_rate\"])\n",
        "        self.blocks = nn.ModuleList([TransformerEncoder(config[\"embed_dim\"], config[\"num_heads\"], config[\"mlp_ratio\"], config[\"dropout_rate\"]) for _ in range(config[\"depth\"])])\n",
        "        self.norm = nn.LayerNorm(config[\"embed_dim\"])\n",
        "        self.head = nn.Linear(config[\"embed_dim\"], config[\"num_classes\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.norm(x)\n",
        "        cls_token_final = x[:, 0]\n",
        "        logits = self.head(cls_token_final)\n",
        "        return logits\n",
        "\n",
        "# ==============================================================================\n",
        "# Cell 5: Data Loading and Augmentation\n",
        "# ==============================================================================\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(config[\"image_size\"], scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.TrivialAugmentWide(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2, pin_memory=True)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# Cell 6: Training and Evaluation Loop\n",
        "# ==============================================================================\n",
        "model = VisionTransformer(config).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "# Warmup Scheduler\n",
        "def warmup_cosine_scheduler(epoch):\n",
        "    if epoch < config[\"warmup_epochs\"]:\n",
        "        return float(epoch) / float(max(1, config[\"warmup_epochs\"]))\n",
        "    else:\n",
        "        progress = float(epoch - config[\"warmup_epochs\"]) / float(max(1, config[\"num_epochs\"] - config[\"warmup_epochs\"]))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=warmup_cosine_scheduler)\n",
        "\n",
        "\n",
        "def train_one_epoch(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\")\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(progress_bar):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        # Gradient Clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix(loss=running_loss/(i+1), acc=f\"{(100.*correct/total):.2f}%\")\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    accuracy = 100. * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# ==============================================================================\n",
        "# Cell 7: Run Training\n",
        "# ==============================================================================\n",
        "best_accuracy = 0.0\n",
        "for epoch in range(config[\"num_epochs\"]):\n",
        "    train_one_epoch(epoch)\n",
        "    current_accuracy = test(epoch)\n",
        "    scheduler.step()\n",
        "\n",
        "    if current_accuracy > best_accuracy:\n",
        "        best_accuracy = current_accuracy\n",
        "        print(f\"🎉 New best accuracy at epoch {epoch+1}: {best_accuracy:.2f}%\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch+1} Test Accuracy: {current_accuracy:.2f}% (Best: {best_accuracy:.2f}%)\")\n",
        "\n",
        "print(f\"\\n🏁 Training Finished! Best Test Accuracy: {best_accuracy:.2f}%\")"
      ]
    }
  ]
}